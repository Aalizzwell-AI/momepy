#!/usr/bin/env python
# -*- coding: utf-8 -*-

# elements.py
# generating derived elements (street edge, block)
import geopandas as gpd
import pandas as pd
from tqdm import tqdm  # progress bar
import math
from rtree import index
from osgeo import ogr
from shapely.wkt import loads
import numpy as np
from scipy.spatial import Voronoi
from shapely.geometry import Point, MultiPoint, LineString, Polygon
import shapely.ops
import osmnx as ox
import operator


def clean_buildings(objects, height_column):
    """
    Clean building geometry.

    Delete building with zero height (to avoid division by 0). Be careful, this might
    negatively affect your analysis.

    Parameters
    ----------
    objects : GeoDataFrame
        GeoDataFrame containing objects to analyse
    height_column : str
        name of the column of objects gdf where is stored height value

    Returns
    -------
    GeoDataFrame
    """

    objects = objects[objects[height_column] > 0]
    print('Zero height buildings ommited.')
    return objects


def clean_null(objects):
    """
    Clean null geometry.

    Delete rows of GeoDataFrame with null geometry.

    Parameters
    ----------
    objects : GeoDataFrame
        GeoDataFrame containing objects to analyse

    Returns
    -------
    GeoDataFrame
    """
    objects_none = objects[objects['geometry'].notnull()]  # filter nulls
    return objects_none


def unique_id(objects):
    """
    Add an attribute with unique ID to each row of GeoDataFrame.

    Parameters
    ----------
    objects : GeoDataFrame
        GeoDataFrame containing objects to analyse

    Returns
    -------
    Series
        Series containing resulting values.

    """
    # define empty list for results
    id_list = []
    id = 1
    for idx, row in tqdm(objects.iterrows(), total=objects.shape[0]):
        id_list.append(id)
        id = id + 1

    series = pd.Series(id_list)
    return series


def tessellation(buildings, unique_id='uID', cut_buffer=50, queen_corners=False, minimum=2):
    """
    Generate morphological tessellation around given buildings.

    Parameters
    ----------
    buildings : GeoDataFrame
        GeoDataFrame containing building footprints
    unique_id : str
        name of the column with unique id. If there is none, it could be generated by unique_id().
    cut_buffer : float
        buffer around buildings limiting the extend of tessellation

    Returns
    -------
    GeoDataFrame
        GeoDataFrame of morphological tessellation with the unique id based on original buildings.

    Notes
    -------
    Fix saw-like geometry.
    """
    # reprojected_crs = buildings.crs.copy()
    #
    # reprojected_crs['x_0'] = 0
    # reprojected_crs['y_0'] = 0

    bounds = buildings['geometry'].bounds
    centre_x = -(bounds['maxx'].max() + bounds['minx'].min()) / 2
    centre_y = -(bounds['maxy'].max() + bounds['miny'].min()) / 2
    objects = buildings.copy()
    objects['geometry'] = objects['geometry'].translate(xoff=centre_x, yoff=centre_y)

    # objects = buildings.to_crs(reprojected_crs)

    from timeit import default_timer as timer
    tqdm.pandas()
    start = timer()
    start_ = timer()
    # buffer geometry to resolve shared walls
    print('Bufferring geometry...')
    objects['geometry'] = objects.geometry.progress_apply(lambda g: g.buffer(-0.5, cap_style=2, join_style=2))
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Simplifying geometry...')
    # simplify geometry before Voronoi
    objects['geometry'] = objects.simplify(0.25, preserve_topology=True)
    obj_simple = objects.copy()

    # generate built_up area around buildings to resolve the edge
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Preparing buffer zone for edge resolving (buffering)...')
    obj_simple['geometry'] = obj_simple.buffer(cut_buffer)
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Preparing buffer zone for edge resolving (dissolving)...')
    obj_simple['diss'] = 0
    built_up = obj_simple.dissolve(by='diss')
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Preparing buffer zone for edge resolving (convex hull)...')
    hull = built_up.convex_hull.buffer(cut_buffer)
    print('Done in', timer() - start, 'seconds')

    # densify geometry before Voronoi tesselation
    def densify(geom):
        wkt = geom.wkt  # shapely Polygon to wkt
        geom = ogr.CreateGeometryFromWkt(wkt)  # create ogr geometry
        geom.Segmentize(2)  # densify geometry by 2 metres
        wkt2 = geom.ExportToWkt()  # ogr geometry to wkt
        new = loads(wkt2)  # wkt to shapely Polygon
        return new

    start = timer()
    print('Densifying geometry...')
    objects['geometry'] = objects['geometry'].progress_map(densify)

    # resolve multipart polygons, singlepart are needed
    def multi2single(gpdf):
        gpdf_singlepoly = gpdf[gpdf.geometry.type == 'Polygon']
        gpdf_multipoly = gpdf[gpdf.geometry.type == 'MultiPolygon']

        for i, row in gpdf_multipoly.iterrows():
            Series_geometries = pd.Series(row.geometry)
            df = pd.concat([gpd.GeoDataFrame(row, crs=gpdf_multipoly.crs).T] * len(Series_geometries), ignore_index=True)
            df['geometry'] = Series_geometries
            gpdf_singlepoly = pd.concat([gpdf_singlepoly, df])

        gpdf_singlepoly.reset_index(inplace=True, drop=True)
        return gpdf_singlepoly

    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Converting multipart geometry to singlepart...')
    objects = multi2single(objects)

    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Generating input point array...')

    list_points = []
    for idx, row in tqdm(objects.iterrows(), total=objects.shape[0]):
        poly_ext = row['geometry'].boundary
        if poly_ext is not None:
            if poly_ext.type is 'MultiLineString':
                for line in poly_ext:
                    point_coords = line.coords
                    row_array = np.array(point_coords).tolist()
                    for i in range(len(row_array)):
                        list_points.append(row_array[i])
            elif poly_ext.type is 'LineString':
                point_coords = poly_ext.coords
                row_array = np.array(point_coords).tolist()
                for i in range(len(row_array)):
                    list_points.append(row_array[i])
            else:
                raise Exception('Boundary type is {}'.format(poly_ext.type))

    # add hull
    point_coords = hull[0].boundary.coords
    row_array = np.array(point_coords).tolist()
    for i in range(len(row_array)):
        list_points.append(row_array[i])

    voronoi_points = np.array(list_points)

    # make voronoi diagram
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Generating Voronoi diagram...')
    voronoi_diagram = Voronoi(voronoi_points)
    # generate lines from scipy voronoi output
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Generating Voronoi ridges...')
    lines = [LineString(voronoi_diagram.vertices[line]) for line in voronoi_diagram.ridge_vertices if -1 not in line]

    # generate dataframe with polygons clipped by built_up
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Generating Voronoi geometry...')
    result = pd.DataFrame({'geometry':
                          [poly for poly in shapely.ops.polygonize(lines)]})

    # generate geoDataFrame of Voronoi polygons
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Generating GeoDataFrame of Voronoi polygons...')
    voronoi_polygons = gpd.GeoDataFrame(result, geometry='geometry')
    voronoi_polygons = voronoi_polygons.loc[voronoi_polygons['geometry'].length < 1000000]
    # set crs
    voronoi_polygons.crs = objects.crs
    print('Done in', timer() - start, 'seconds')

    start = timer()
    print('Generating MultiPoint geometry...')

    def pointize(geom):
        multipoint = []
        if geom.boundary.type is 'MultiLineString':
            for line in geom.boundary:
                arr = line.coords.xy
                for p in range(len(arr[0])):
                    point = (arr[0][p], arr[1][p])
                    multipoint.append(point)
        elif geom.boundary.type is 'LineString':
            arr = geom.boundary.coords.xy
            for p in range(len(arr[0])):
                point = (arr[0][p], arr[1][p])
                multipoint.append(point)
        else:
            raise Exception('Boundary type is {}'.format(geom.boundary.type))
        new = MultiPoint(list(set(multipoint)))
        return new

    objects_none = objects[objects['geometry'].notnull()]
    objects_none['geometry'] = objects_none['geometry'].progress_map(pointize)
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Spatial join of MultiPoint geometry and Voronoi polygons...')
    # spatial join
    objects_none = objects_none.dropna(subset=['geometry'])
    voronoi_with_id = gpd.sjoin(voronoi_polygons, objects_none, how='left')
    voronoi_with_id.crs = objects.crs

    # resolve thise cells which were not joined spatially (again, due to unprecision caused by scipy Voronoi function)
    # select those unjoined
    unjoined = voronoi_with_id[voronoi_with_id[unique_id].isnull()]
    print('Done in', timer() - start, 'seconds')
    if len(unjoined.index) > 0:
        start = timer()
        print('Fixing unjoined geometry:', len(unjoined.index), 'problems...')
        # for each polygon, find neighbours, measure boundary and set uID to the most neighbouring one
        print(' Building R-tree...')
        join_index = voronoi_with_id.sindex
        print(' Done in', timer() - start, 'seconds')
        start = timer()
        for idx, row in tqdm(unjoined.iterrows(), total=unjoined.shape[0]):
            neighbors = list(join_index.intersection(row.geometry.bounds))  # find neigbours
            neighbors_ids = []
            for n in neighbors:
                neighbors_ids.append(voronoi_with_id.iloc[n][unique_id])
            neighbors_ids = [x for x in neighbors_ids if str(x) != 'nan']  # remove polygon itself

            global boundaries
            boundaries = {}
            for i in neighbors_ids:
                subset = voronoi_with_id.loc[voronoi_with_id[unique_id] == i]['geometry']
                le = 0
                for s in subset:
                    le = le + row.geometry.intersection(s).length
                boundaries[i] = le

            voronoi_with_id.loc[idx, unique_id] = max(boundaries.items(), key=operator.itemgetter(1))[0]

        unjoined2 = voronoi_with_id[voronoi_with_id[unique_id].isnull()]
        if len(unjoined2.index) is not 0:
            raise Exception('Some geometry remained unfinxed: {} problems'.format(len(unjoined2.index)))
        # dissolve polygons by unique_id
        print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Dissolving Voronoi polygons...')
    voronoi_with_id['geometry'] = voronoi_with_id.buffer(0)
    voronoi_plots = voronoi_with_id.dissolve(by=unique_id)
    voronoi_plots[unique_id] = voronoi_plots.index.astype('float')  # save unique id to column from index

    # cut infinity of voronoi by set buffer (thanks for script to Geoff Boeing)
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Preparing buffer zone for edge resolving (quadrat cut)...')
    geometry = built_up['geometry'].iloc[0].boundary
    # quadrat_width is in the units the geometry is in
    geometry_cut = ox.quadrat_cut_geometry(geometry, quadrat_width=100)

    # build the r-tree index
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Building R-tree...')
    sindex = voronoi_plots.sindex
    # find the points that intersect with each subpolygon and add them to points_within_geometry
    to_cut = pd.DataFrame()
    for poly in geometry_cut:
        # find approximate matches with r-tree, then precise matches from those approximate ones
        possible_matches_index = list(sindex.intersection(poly.bounds))
        possible_matches = voronoi_plots.iloc[possible_matches_index]
        precise_matches = possible_matches[possible_matches.intersects(poly)]
        to_cut = to_cut.append(precise_matches)

    # delete duplicates
    to_cut = to_cut.drop_duplicates(subset=[unique_id])
    subselection = list(to_cut.index)
    print('Done in', timer() - start, 'seconds')
    start = timer()
    print('Cutting...')
    for idx, row in tqdm(voronoi_plots.loc[subselection].iterrows(), total=voronoi_plots.loc[subselection].shape[0]):
        intersection = row.geometry.intersection(built_up['geometry'].iloc[0])
        if intersection.type == 'MultiPolygon':
            areas = {}
            for p in range(len(intersection)):
                area = intersection[p].area
                areas[p] = area
            maximal = max(areas.items(), key=operator.itemgetter(1))[0]
            voronoi_plots.loc[idx, 'geometry'] = intersection[maximal]
        elif intersection.type == 'GeometryCollection':
            for geom in list(intersection.geoms):
                    if geom.type != 'Polygon':
                        pass
                    else:
                        voronoi_plots.loc[idx, 'geometry'] = geom
        else:
            voronoi_plots.loc[idx, 'geometry'] = intersection

    voronoi_plots = voronoi_plots.drop(['index_right'], axis=1)

    voronoi_plots['geometry'] = voronoi_plots['geometry'].translate(xoff=-centre_x, yoff=-centre_y)

    morphological_tessellation = voronoi_plots
    morphological_tessellation.reset_index(drop=True, inplace=True)

    ids_original = list(buildings[unique_id])
    ids_generated = list(morphological_tessellation[unique_id])
    if len(ids_original) != len(ids_generated):
        import warnings
        diff = set(ids_original).difference(ids_generated)
        warnings.warn("Tessellation does not fully match buildings. {len} element(s) collapsed "
                      "during generation - unique_id: {i}".format(len=len(diff), i=diff))

    uids = morphological_tessellation[morphological_tessellation.geometry.type == 'MultiPolygon'][unique_id]
    if len(uids) is not 0:
        import warnings
        warnings.warn('Tessellation contains MultiPolygon elements. Initial objects should be edited. '
                      'unique_id of affected elements: {}'.format(list(uids)))

    if queen_corners is True:
        print('Generating queen corners...')
        print(' Generating spatial index...')
        sindex = morphological_tessellation.sindex
        changes = {}
        # detect points which should be changed and calculate new coordinates
        print(' Detecting points of change...')
        for ix, row in tqdm(morphological_tessellation.iterrows(), total=morphological_tessellation.shape[0]):
            corners = []
            change = []
            cell = row.geometry
            coords = cell.exterior.coords
            for i in coords:
                point = Point(i)
                possible_matches_index = list(sindex.intersection(point.bounds))
                possible_matches = morphological_tessellation.iloc[possible_matches_index]
                precise_matches = sum(possible_matches.intersects(point))
                if precise_matches > 2:
                    corners.append(point)

            if len(corners) > 2:
                for c in range(len(corners)):
                    next = c + 1
                    if c == (len(corners) - 1):
                        next = 0
                    if corners[c].distance(corners[next]) < minimum:
                        change.append([corners[c], corners[next]])
            elif len(corners) == 2:
                if corners[0].distance(corners[1]) > 0:
                    if corners[0].distance(corners[1]) < minimum:
                        change.append([corners[0], corners[1]])

            if len(change) > 0:
                for points in change:
                    x_new = np.mean([points[0].x, points[1].x])
                    y_new = np.mean([points[0].y, points[1].y])
                    new = (x_new, y_new)
                    changes[(points[0].x, points[0].y)] = new
                    changes[(points[1].x, points[1].y)] = new

        print(' Generating new geometry...')
        for ix, row in tqdm(morphological_tessellation.iterrows(), total=morphological_tessellation.shape[0]):
            cell = row.geometry
            coords = list(cell.exterior.coords)
            newcoords = [changes[x] if x in changes.keys() else x for x in coords]
            if coords != newcoords:
                newgeom = Polygon(newcoords).buffer(0)
                if newgeom.type == 'MultiPolygon':
                    morphological_tessellation.loc[ix, 'geometry'] = newgeom[0]
                    print(row.uID)
                else:
                    morphological_tessellation.loc[ix, 'geometry'] = newgeom

    print('Done in', timer() - start, 'seconds')
    print('Done. Tessellation finished in', timer() - start_, 'seconds.')
    return morphological_tessellation


def snap_street_network_edge(network, buildings, tessellation, tolerance_street, tolerance_edge):
    """
    Fix street network before performing blocks()

    Extends unjoined ends of street segments to join with other segmets or tessellation boundary.

    Parameters
    ----------
    network : GeoDataFrame
        GeoDataFrame containing street network
    buildings : GeoDataFrame
        GeoDataFrame containing building footprints
    tessellation : GeoDataFrame
        GeoDataFrame containing morphological tessellation
    tolerance_street : float
        tolerance in snapping to street network (by how much could be street segment extended).
    tolerance_edge : float
        tolerance in snapping to edge of tessellated area (by how much could be street segment extended).

    Returns
    -------
    GeoDataFrame
        GeoDataFrame of extended street network.

    """
    # extrapolating function - makes line as a extrapolation of existing with set length (tolerance)
    def getExtrapoledLine(p1, p2, tolerance):
        """
        Creates a line extrapoled in p1->p2 direction.
        """
        EXTRAPOL_RATIO = tolerance  # length of a line
        a = p2

        # defining new point based on the vector between existing points
        if p1[0] >= p2[0] and p1[1] >= p2[1]:
            b = (p2[0] - EXTRAPOL_RATIO * math.cos(math.atan(math.fabs(p1[1] - p2[1] + 0.000001) / math.fabs(p1[0] - p2[0] + 0.000001))),
                 p2[1] - EXTRAPOL_RATIO * math.sin(math.atan(math.fabs(p1[1] - p2[1] + 0.000001) / math.fabs(p1[0] - p2[0] + 0.000001))))
        elif p1[0] <= p2[0] and p1[1] >= p2[1]:
            b = (p2[0] + EXTRAPOL_RATIO * math.cos(math.atan(math.fabs(p1[1] - p2[1] + 0.000001) / math.fabs(p1[0] - p2[0] + 0.000001))),
                 p2[1] - EXTRAPOL_RATIO * math.sin(math.atan(math.fabs(p1[1] - p2[1] + 0.000001) / math.fabs(p1[0] - p2[0] + 0.000001))))
        elif p1[0] <= p2[0] and p1[1] <= p2[1]:
            b = (p2[0] + EXTRAPOL_RATIO * math.cos(math.atan(math.fabs(p1[1] - p2[1] + 0.000001) / math.fabs(p1[0] - p2[0] + 0.000001))),
                 p2[1] + EXTRAPOL_RATIO * math.sin(math.atan(math.fabs(p1[1] - p2[1] + 0.000001) / math.fabs(p1[0] - p2[0] + 0.000001))))
        else:
            b = (p2[0] - EXTRAPOL_RATIO * math.cos(math.atan(math.fabs(p1[1] - p2[1] + 0.000001) / math.fabs(p1[0] - p2[0] + 0.000001))),
                 p2[1] + EXTRAPOL_RATIO * math.sin(math.atan(math.fabs(p1[1] - p2[1] + 0.000001) / math.fabs(p1[0] - p2[0] + 0.000001))))
        return LineString([a, b])

    # function extending line to closest object within set distance
    def extend_line(tolerance):
        """
        Extends a line geometry withing GeoDataFrame to snap on itself withing tolerance.
        """
        if Point(l_coords[-2]).distance(Point(l_coords[-1])) <= 0.001:
            extra = l_coords[-3:-1]
        else:
            extra = l_coords[-2:]
        extrapolation = getExtrapoledLine(*extra, tolerance)  # we use the last two points

        possible_intersections_index = list(sindex.intersection(extrapolation.bounds))
        possible_intersections_lines = network.iloc[possible_intersections_index]
        possible_intersections_clean = possible_intersections_lines.drop(idx, axis=0)
        possible_intersections = possible_intersections_clean.intersection(extrapolation)

        if possible_intersections.any():

            true_int = []
            for one in list(possible_intersections.index):
                if possible_intersections[one].type == 'Point':
                    true_int.append(possible_intersections[one])
                elif possible_intersections[one].type == 'MultiPoint':
                    true_int.append(possible_intersections[one][0])
                    true_int.append(possible_intersections[one][1])

            if len(true_int) > 1:
                distances = {}
                ix = 0
                for p in true_int:
                    distance = p.distance(Point(l_coords[-1]))
                    distances[ix] = distance
                    ix = ix + 1
                minimal = min(distances.items(), key=operator.itemgetter(1))[0]
                new_point_coords = true_int[minimal].coords[0]
            else:
                new_point_coords = true_int[0].coords[0]

            l_coords.append(new_point_coords)
            new_extended_line = LineString(l_coords)

            # check whether the line goes through buildings. if so, ignore it
            possible_buildings_index = list(bindex.intersection(new_extended_line.bounds))
            possible_buildings = buildings.iloc[possible_buildings_index]
            possible_intersections = possible_buildings.intersection(new_extended_line)

            if possible_intersections.any():
                pass
            else:
                network.loc[idx, 'geometry'] = new_extended_line
        else:
            return False

    # function extending line to closest object within set distance to edge defined by tessellation
    def extend_line_edge(tolerance):
        """
        Extends a line geometry withing GeoDataFrame to snap on the boundary of tessellation withing tolerance.
        """
        if Point(l_coords[-2]).distance(Point(l_coords[-1])) <= 0.001:
            extra = l_coords[-3:-1]
        else:
            extra = l_coords[-2:]
        extrapolation = getExtrapoledLine(*extra, tolerance)  # we use the last two points

        # possible_intersections_index = list(qindex.intersection(extrapolation.bounds))
        # possible_intersections_lines = geometry_cut.iloc[possible_intersections_index]
        possible_intersections = geometry.intersection(extrapolation)

        if possible_intersections.type != 'GeometryCollection':

            true_int = []

            if possible_intersections.type == 'Point':
                true_int.append(possible_intersections)
            elif possible_intersections.type == 'MultiPoint':
                true_int.append(possible_intersections[0])
                true_int.append(possible_intersections[1])

            if len(true_int) > 1:
                distances = {}
                ix = 0
                for p in true_int:
                    distance = p.distance(Point(l_coords[-1]))
                    distances[ix] = distance
                    ix = ix + 1
                minimal = min(distances.items(), key=operator.itemgetter(1))[0]
                new_point_coords = true_int[minimal].coords[0]
            else:
                new_point_coords = true_int[0].coords[0]

            l_coords.append(new_point_coords)
            new_extended_line = LineString(l_coords)

            # check whether the line goes through buildings. if so, ignore it
            possible_buildings_index = list(bindex.intersection(new_extended_line.bounds))
            possible_buildings = buildings.iloc[possible_buildings_index]
            possible_intersections = possible_buildings.intersection(new_extended_line)

            if possible_intersections.any():
                pass
            else:
                network.loc[idx, 'geometry'] = new_extended_line

    # generating spatial index (rtree)
    print('Building R-tree for network...')
    sindex = network.sindex
    print('Building R-tree for buildings...')
    bindex = buildings.sindex
    print('Dissolving tesselation...')
    tessellation['diss'] = 0
    built_up = tessellation.dissolve(by='diss')
    geometry = built_up['geometry'].iloc[0].boundary

    print('Snapping...')
    # iterating over each street segment
    for idx, row in tqdm(network.iterrows(), total=network.shape[0]):

        line = row['geometry']
        l_coords = list(line.coords)
        # network_w = network.drop(idx, axis=0)['geometry']  # ensure that it wont intersect itself
        start = Point(l_coords[0])
        end = Point(l_coords[-1])

        # find out whether ends of the line are connected or not
        possible_first_index = list(sindex.intersection(start.bounds))
        possible_first_matches = network.iloc[possible_first_index]
        possible_first_matches_clean = possible_first_matches.drop(idx, axis=0)
        first = possible_first_matches_clean.intersects(start).any()

        possible_second_index = list(sindex.intersection(end.bounds))
        possible_second_matches = network.iloc[possible_second_index]
        possible_second_matches_clean = possible_second_matches.drop(idx, axis=0)
        second = possible_second_matches_clean.intersects(end).any()

        # both ends connected, do nothing
        if first == True and second == True:
            continue
        # start connected, extend  end
        elif first == True and second == False:
            if extend_line(tolerance_street) is False:
                extend_line_edge(tolerance_edge)
        # end connected, extend start
        elif first == False and second == True:
            l_coords.reverse()
            if extend_line(tolerance_street) is False:
                extend_line_edge(tolerance_edge)
        # unconnected, extend both ends
        elif first == False and second == False:
            if extend_line(tolerance_street) is False:
                extend_line_edge(tolerance_edge)
            l_coords.reverse()
            if extend_line(tolerance_street) is False:
                extend_line_edge(tolerance_edge)
        else:
            print('Something went wrong.')

    return network


def blocks(cells, streets, buildings, id_name, unique_id):
    """
    Generate blocks based on buildings, tesselation and street network

    Adds bID to buildings and tesselation.

    Parameters
    ----------
    cells : GeoDataFrame
        GeoDataFrame containing morphological tessellation
    streets : GeoDataFrame
        GeoDataFrame containing street network
    buildings : GeoDataFrame
        GeoDataFrame containing buildings
    id_name : str
        name of the unique blocks id column to be generated
    unique_id : str
        name of the column with unique id. If there is none, it could be generated by unique_id().
        This should be the same for cells and buildings, id's should match.

    Returns
    -------
    buildings, cells, blocks : tuple

    buildings : GeoDataFrame
        GeoDataFrame containing buildings with added block ID
    cells : GeoDataFrame
        GeoDataFrame containing morphological tessellation with added block ID
    blocks : GeoDataFrame
        GeoDataFrame containing generated blocks
    """

    cells_copy = cells.copy()
    print('Dissolving tesselation...')
    built_up = cells.geometry.unary_union

    print('Buffering streets...')
    street_buff = streets.copy()
    street_buff['geometry'] = streets.buffer(0.1)

    print('Dissolving streets...')
    street_cut = street_buff.unary_union

    print('Defining street-based blocks...')
    street_blocks = built_up.difference(street_cut)

    blocks_gdf = gpd.GeoDataFrame(geometry=gpd.GeoSeries(street_blocks))

    def multi2single(gpdf):
        gpdf_singlepoly = gpdf[gpdf.geometry.type == 'Polygon']
        gpdf_multipoly = gpdf[gpdf.geometry.type == 'MultiPolygon']

        for i, row in gpdf_multipoly.iterrows():
            Series_geometries = pd.Series(row.geometry)
            df = pd.concat([gpd.GeoDataFrame(row, crs=gpdf_multipoly.crs).T] * len(Series_geometries), ignore_index=True)
            df['geometry'] = Series_geometries
            gpdf_singlepoly = pd.concat([gpdf_singlepoly, df])

        gpdf_singlepoly.reset_index(inplace=True, drop=True)
        return gpdf_singlepoly

    print('Multipart to singlepart...')
    blocks_single = multi2single(blocks_gdf)

    blocks_single['geometry'] = blocks_single.buffer(0.1)

    print('Defining block ID...')  # street based
    blocks_single[id_name] = None
    blocks_single[id_name] = blocks_single[id_name].astype('float')
    id = 1
    for idx, row in tqdm(blocks_single.iterrows(), total=blocks_single.shape[0]):
        blocks_single.loc[idx, id_name] = id
        id = id + 1

    print('Generating centroids...')
    buildings_c = buildings.copy()
    buildings_c['geometry'] = buildings_c.centroid  # make centroids
    blocks_single.crs = buildings.crs

    print('Spatial join...')
    centroids_tempID = gpd.sjoin(buildings_c, blocks_single, how='left', op='intersects')

    tempID_to_uID = centroids_tempID[[unique_id, id_name]]

    print('Attribute join (tesselation)...')
    cells_copy = cells_copy.merge(tempID_to_uID, on=unique_id)

    print('Generating blocks...')
    blocks = cells_copy.dissolve(by=id_name)
    cells_copy = cells_copy.drop([id_name], axis=1)

    print('Multipart to singlepart...')
    blocks = multi2single(blocks)

    blocks['geometry'] = blocks.exterior

    id = 1
    for idx, row in tqdm(blocks.iterrows(), total=blocks.shape[0]):
        blocks.loc[idx, id_name] = id
        id = id + 1
        blocks.loc[idx, 'geometry'] = Polygon(row['geometry'])

    # if polygon is within another one, delete it
    sindex = blocks.sindex
    for idx, row in tqdm(blocks.iterrows(), total=blocks.shape[0]):
        possible_matches = list(sindex.intersection(row.geometry.bounds))
        possible_matches.remove(idx)
        possible = blocks.iloc[possible_matches]

        for idx2, row2 in possible.iterrows():
            if row['geometry'].within(row2['geometry']):
                blocks.loc[idx, 'delete'] = 1

    if 'delete' in blocks.columns:
        blocks = blocks.drop(list(blocks.loc[blocks['delete'] == 1].index))

    blocks_save = blocks[[id_name, 'geometry']]
    # blocks_save['geometry'] = blocks_save.buffer(0.000000001)

    centroids_w_bl_ID2 = gpd.sjoin(buildings_c, blocks_save, how='left', op='intersects')
    bl_ID_to_uID = centroids_w_bl_ID2[[unique_id, id_name]]

    print('Attribute join (buildings)...')
    buildings = buildings.merge(bl_ID_to_uID, on=unique_id)

    print('Attribute join (tesselation)...')
    cells = cells.merge(bl_ID_to_uID, on=unique_id)

    print('Done')
    return (buildings, cells, blocks_save)

# '''
# street_edges():
#
# Generate street edges based on buildings, blocks, tesselation and street network with street names
# Adds nID and eID to buildings and tesselation.
#
#     buildings = gdf of buildings (with unique id)
#     streets = gdf of street network (with street names and unique network segment id)
#     tesselation = gdf of tesselation (with unique id and block id)
#     street_name_column = column with street names
#     unique_id_column = column with unique ids
#     block_id_column = column with block ids
#     network_id_column = column with network ids
#     tesselation_to = path to save tesselation with nID, eID
#     buildings_to = path to save buildings with nID, eID
#     save_to = path to save street edges
#
# Optional:
# '''
#
#
# def street_edges(buildings, streets, tesselation, street_name_column,
#                  unique_id_column, block_id_column, network_id_column,
#                  tesselation_to, buildings_to, save_to):
#     INFTY = 1000000000000
#     MIN_SIZE = 100
#     # MIN_SIZE should be a vaule such that if you build a box centered in each
#     # point with edges of size 2*MIN_SIZE, you know a priori that at least one
#     # segment is intersected with the box. Otherwise, you could get an inexact
#     # solution, there is an exception checking this, though.
#
#     def distance(a, b):
#         return math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)
#
#     def get_distance(apoint, segment):
#         a = apoint
#         b, c = segment
#         # t = <a-b, c-b>/|c-b|**2
#         # because p(a) = t*(c-b)+b is the ortogonal projection of vector a
#         # over the rectline that includes the points b and c.
#         t = (a[0] - b[0]) * (c[0] - b[0]) + (a[1] - b[1]) * (c[1] - b[1])
#         t = t / ((c[0] - b[0]) ** 2 + (c[1] - b[1]) ** 2)
#         # Only if t 0 <= t <= 1 the projection is in the interior of
#         # segment b-c, and it is the point that minimize the distance
#         # (by pythagoras theorem).
#         if 0 < t < 1:
#             pcoords = (t * (c[0] - b[0]) + b[0], t * (c[1] - b[1]) + b[1])
#             dmin = distance(a, pcoords)
#             return pcoords, dmin
#         elif t <= 0:
#             return b, distance(a, b)
#         elif 1 <= t:
#             return c, distance(a, c)
#
#     def get_rtree(lines):
#         def generate_items():
#             sindx = 0
#             for lid, nid, l in tqdm(lines, total=len(lines)):
#                 for i in range(len(l) - 1):
#                     a, b = l[i]
#                     c, d = l[i + 1]
#                     segment = ((a, b), (c, d))
#                     box = (min(a, c), min(b, d), max(a, c), max(b, d))
#                     # box = left, bottom, right, top
#                     yield (sindx, box, (lid, segment, nid))
#                     sindx += 1
#         return index.Index(generate_items())
#
#     def get_solution(idx, points):
#         result = {}
#         for p in tqdm(points, total=len(points)):
#             pbox = (p[0] - MIN_SIZE, p[1] - MIN_SIZE, p[0] + MIN_SIZE, p[1] + MIN_SIZE)
#             hits = idx.intersection(pbox, objects='raw')
#             d = INFTY
#             s = None
#             for h in hits:
#                 nearest_p, new_d = get_distance(p, h[1])
#                 if d >= new_d:
#                     d = new_d
#                     # s = (h[0], h[1], nearest_p, new_d)
#                     s = (h[0], h[1], h[-1])
#             result[p] = s
#             if s is None:
#                 result[p] = (0, 0)
#
#             # some checking you could remove after you adjust the constants
#             # if s is None:
#             #     raise Warning("It seems INFTY is not big enough. Point was not attached to street. It might be too far.", p)
#
#             # pboxpol = ((pbox[0], pbox[1]), (pbox[2], pbox[1]),
#             #            (pbox[2], pbox[3]), (pbox[0], pbox[3]))
#             # if not Polygon(pboxpol).intersects(LineString(s[1])):
#             #     msg = "It seems MIN_SIZE is not big enough. "
#             #     msg += "You could get inexact solutions if remove this exception."
#             #     raise Exception(msg)
#
#         return result
#
#     print('Generating centroids...')
#     buildings_c = buildings.copy()
#     buildings_c['geometry'] = buildings_c.centroid  # make centroids
#
#     print('Generating list of points...')
#     # make points list for input
#     centroid_list = []
#     for idx, row in tqdm(buildings_c.iterrows(), total=buildings_c.shape[0]):
#         centroid_list = centroid_list + list(row['geometry'].coords)
#
#     print('Generating list of lines...')
#     # make streets list for input
#     street_list = []
#     for idx, row in tqdm(streets.iterrows(), total=streets.shape[0]):
#         street_list.append((row[street_name_column], row[network_id_column], list(row['geometry'].coords)))
#     print('Generating rtree...')
#     idx = get_rtree(street_list)
#
#     print('Snapping...')
#     solutions = get_solution(idx, centroid_list)
#
#     print('Forming DataFrame...')
#     df = pd.DataFrame.from_dict(solutions, orient='index', columns=['street', 'unused', network_id_column])  # solutions dict to df
#     df['point'] = df.index  # point to column
#     df = df.reset_index()
#     df['idx'] = df.index
#     buildings_c['idx'] = buildings_c.index
#
#     print('Joining DataFrames...')
#     joined = buildings_c.merge(df, on='idx')
#     print('Cleaning DataFrames...')
#     cleaned = joined[[unique_id_column, 'street', network_id_column]]
#
#     print('Merging with tesselation...')
#     tesselation = tesselation.merge(cleaned, on=unique_id_column)
#
#     print('Defining merge ID...')
#     for idx, row in tqdm(tesselation.iterrows(), total=tesselation.shape[0]):
#         tesselation.loc[idx, 'mergeID'] = str(row['street']) + str(row[block_id_column])
#
#     print('Dissolving...')
#     edges = tesselation.dissolve(by='mergeID')
#
#     # multipart geometry to singlepart
#     def multi2single(gpdf):
#         gpdf_singlepoly = gpdf[gpdf.geometry.type == 'Polygon']
#         gpdf_multipoly = gpdf[gpdf.geometry.type == 'MultiPolygon']
#
#         for i, row in gpdf_multipoly.iterrows():
#             Series_geometries = pd.Series(row.geometry)
#             df = pd.concat([gpd.GeoDataFrame(row, crs=gpdf_multipoly.crs).T] * len(Series_geometries), ignore_index=True)
#             df['geometry'] = Series_geometries
#             gpdf_singlepoly = pd.concat([gpdf_singlepoly, df])
#
#         gpdf_singlepoly.reset_index(inplace=True, drop=True)
#         return gpdf_singlepoly
#
#     edges_single = multi2single(edges)
#     edges_single['geometry'] = edges_single.exterior
#     print('Generating unique edge ID...')
#     id = 1
#     for idx, row in tqdm(edges_single.iterrows(), total=edges_single.shape[0]):
#         edges_single.loc[idx, 'eID'] = id
#         id = id + 1
#         edges_single.loc[idx, 'geometry'] = Polygon(row['geometry'])
#
#     edges_clean = edges_single[['geometry', 'eID', block_id_column]]
#
#     print('Isolating islands...')
#     sindex = edges_clean.sindex
#     islands = []
#     for idx, row in edges_clean.iterrows():
#         possible_matches_index = list(sindex.intersection(row['geometry'].bounds))
#         possible_matches = edges_clean.iloc[possible_matches_index]
#         possible_matches = possible_matches.drop([idx], axis=0)
#         if possible_matches.contains(row['geometry']).any():
#             islands.append(idx)
#
#     edges_clean = edges_clean.drop(islands, axis=0)
#     print(len(islands), 'islands deleted.')
#     print('Cleaning edges...')
#     edges_clean['geometry'] = edges_clean.buffer(0.000000001)
#
#     print('Saving street edges to', save_to)
#     edges_clean.to_file(save_to)
#
#     print('Cleaning tesselation...')
#     tesselation = tesselation.drop(['street', 'mergeID'], axis=1)
#
#     print('Tesselation spatial join [1/3]...')
#     tess_centroid = tesselation.copy()
#     tess_centroid['geometry'] = tess_centroid.centroid
#
#     edg_join = edges_clean.drop(['bID'], axis=1)
#
#     print('Tesselation spatial join [2/3]...')
#     tess_with_eID = gpd.sjoin(tess_centroid, edg_join, how='left', op='intersects')
#     tess_with_eID = tess_with_eID[['uID', 'eID']]
#
#     print('Tesselation spatial join [3/3]...')
#     tesselation = tesselation.merge(tess_with_eID, on='uID')
#
#     print('Saving tesselation to', tesselation_to)
#     tesselation.to_file(tesselation_to)
#
#     print('Buildings attribute join...')
#     # attribute join cell -> building
#     tess_nid_eid = tesselation[['uID', 'eID', 'nID']]
#
#     buildings = buildings.merge(tess_nid_eid, on='uID')
#
#     print('Saving buildings to', buildings_to)
#     buildings.to_file(buildings_to)
#
#     print('Done.')


def get_network_id(buildings, streets, tesselation, unique_id_column, network_id_column):
    """
    Snap each building to closest street network segment, saves its id.

    Adds nID to buildings and tesselation.

    Parameters
    ----------
    buildings : GeoDataFrame
        GeoDataFrame containing buildings
    streets : GeoDataFrame
        GeoDataFrame containing street network with unique network ID.
        If there is none, it could be generated by unique_id().
    tesselation : GeoDataFrame
        GeoDataFrame containing morphological tessellation
    unique_id_column : str
        name of the column with unique id. If there is none, it could be generated by unique_id().
        This should be the same for cells and buildings, id's should match.
    network_id_column : str
        name of the column with network unique id.

    buildings_to, tessellation_to

    Returns
    -------
    buildings, tesselation : tuple

    buildings : GeoDataFrame
        GeoDataFrame containing buildings with added network ID
    cells : GeoDataFrame
        GeoDataFrame containing morphological tessellation with added network ID

    """
    INFTY = 1000000000000
    MIN_SIZE = 100
    # MIN_SIZE should be a vaule such that if you build a box centered in each
    # point with edges of size 2*MIN_SIZE, you know a priori that at least one
    # segment is intersected with the box. Otherwise, you could get an inexact
    # solution, there is an exception checking this, though.

    def distance(a, b):
        return math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)

    def get_distance(apoint, segment):
        a = apoint
        b, c = segment
        # t = <a-b, c-b>/|c-b|**2
        # because p(a) = t*(c-b)+b is the ortogonal projection of vector a
        # over the rectline that includes the points b and c.
        t = (a[0] - b[0]) * (c[0] - b[0]) + (a[1] - b[1]) * (c[1] - b[1])
        t = t / ((c[0] - b[0]) ** 2 + (c[1] - b[1]) ** 2)
        # Only if t 0 <= t <= 1 the projection is in the interior of
        # segment b-c, and it is the point that minimize the distance
        # (by pythagoras theorem).
        if 0 < t < 1:
            pcoords = (t * (c[0] - b[0]) + b[0], t * (c[1] - b[1]) + b[1])
            dmin = distance(a, pcoords)
            return pcoords, dmin
        elif t <= 0:
            return b, distance(a, b)
        elif 1 <= t:
            return c, distance(a, c)

    def get_rtree(lines):
        def generate_items():
            sindx = 0
            for nid, l in tqdm(lines, total=len(lines)):
                for i in range(len(l) - 1):
                    a, b = l[i]
                    c, d = l[i + 1]
                    segment = ((a, b), (c, d))
                    box = (min(a, c), min(b, d), max(a, c), max(b, d))
                    # box = left, bottom, right, top
                    yield (sindx, box, (segment, nid))
                    sindx += 1
        return index.Index(generate_items())

    def get_solution(idx, points):
        result = {}
        for p in tqdm(points, total=len(points)):
            pbox = (p[0] - MIN_SIZE, p[1] - MIN_SIZE, p[0] + MIN_SIZE, p[1] + MIN_SIZE)
            hits = idx.intersection(pbox, objects='raw')
            d = INFTY
            s = None
            for h in hits:
                nearest_p, new_d = get_distance(p, h[0])
                if d >= new_d:
                    d = new_d
                    # s = (h[0], h[1], nearest_p, new_d)
                    s = (h[0], h[1], h[-1])
            result[p] = s
            if s is None:
                result[p] = (0, 0)

        return result

    print('Generating centroids...')
    buildings_c = buildings.copy()
    buildings_c['geometry'] = buildings_c.centroid  # make centroids

    print('Generating list of points...')
    # make points list for input
    centroid_list = []
    for idx, row in tqdm(buildings_c.iterrows(), total=buildings_c.shape[0]):
        centroid_list = centroid_list + list(row['geometry'].coords)

    print('Generating list of lines...')
    # make streets list for input
    street_list = []
    for idx, row in tqdm(streets.iterrows(), total=streets.shape[0]):
        street_list.append((row[network_id_column], list(row['geometry'].coords)))
    print('Generating rtree...')
    idx = get_rtree(street_list)

    print('Snapping...')
    solutions = get_solution(idx, centroid_list)

    print('Forming DataFrame...')
    df = pd.DataFrame.from_dict(solutions, orient='index', columns=['unused', 'unused', network_id_column])  # solutions dict to df
    df['point'] = df.index  # point to column
    df = df.reset_index()
    df['idx'] = df.index
    buildings_c['idx'] = buildings_c.index

    print('Joining DataFrames...')
    joined = buildings_c.merge(df, on='idx')
    print('Cleaning DataFrames...')
    cleaned = joined[[unique_id_column, network_id_column]]

    print('Merging with tesselation...')
    tesselation = tesselation.merge(cleaned, on=unique_id_column)
    #
    # print('Saving tesselation to', tesselation_to)
    # tesselation.to_file(tesselation_to)

    print('Buildings attribute join...')
    # attribute join cell -> building
    tess_nid_eid = tesselation[['uID', 'nID']]

    buildings = buildings.merge(tess_nid_eid, on='uID')
    #
    # print('Saving buildings to', buildings_to)
    # buildings.to_file(buildings_to)

    print('Done.')
    return (buildings, tesselation)
